# ğŸ¥ ETL Claims â€“ LaSante  

This project implements an **ETL pipeline** in Python to process medical claim data from SQL Server.  

The pipeline includes:  
- **Extract** â†’ retrieves base tables from SQL Server  
- **Transform** â†’ cleans and combines into intermediate datasets (`invoice`, `claiminsurance`, `payments`, `wrap`)  
- **Load** â†’ exports the final dataset (`claims`) into CSV files (chunks of 2000 rows)  

## ğŸ“‚ Project structure  

ETL_Claims/  
â”‚  
â”œâ”€â”€ config.py                     # SQL Server connection parameters  
â”‚  
â”œâ”€â”€ extract/  
â”‚   â””â”€â”€ extract_data.py            # Extraction logic for source tables  
â”‚  
â”œâ”€â”€ transform/  
â”‚   â”œâ”€â”€ transform_invoice.py       # Build invoice dataset  
â”‚   â”œâ”€â”€ transform_claiminsurance.py # Clean ClaimInsurance dataset  
â”‚   â”œâ”€â”€ transform_payments.py      # Classify and pivot payments  
â”‚   â”œâ”€â”€ transform_wrap.py          # Classify wrap insurances  
â”‚   â””â”€â”€ transform_claims.py        # Final claims dataset  
â”‚  
â”œâ”€â”€ load/  
â”‚   â””â”€â”€ load_data.py               # Export CSV in 2000-row chunks  
â”‚  
â””â”€â”€ main.py                        # ETL orchestrator  

## âš™ï¸ Configuration  

- **Database connection** â†’ set credentials inside `config.py`:  
```python
DB_SERVER = "your-server"
DB_DATABASE = "your-database"
DB_USER = "your-username"
DB_PASS = "your-password"

